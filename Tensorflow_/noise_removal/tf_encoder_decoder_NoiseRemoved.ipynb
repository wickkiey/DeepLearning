{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.data import AUTOTUNE\n",
    "\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (xtrain,_), (xtest,_) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"D:\\digital_enhancement\\images\\training_images\"\n",
    "images = os.listdir(data_dir)\n",
    "images_list = [data_dir + \"/\" + img for img in images]\n",
    "image_count = len(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(images_list, shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list_ds.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(image_count * 0.2)\n",
    "train_ds = list_ds.skip(val_size)\n",
    "val_ds = list_ds.take(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 640\n",
    "height = 360\n",
    "noise_factor = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  img1 = tf.image.resize(img, [height, width])\n",
    "  img1 = tf.cast(img1, tf.float32) / 255.\n",
    "  img2 = tfa.image.gaussian_filter2d(img1, [5,5])\n",
    "  # Resize the image to the desired size\n",
    "  \n",
    "  # Add gaussian noise\n",
    "  noise_factor = .05\n",
    "  img2 = img2 + noise_factor * ( tf.random.normal(shape=img2.shape)  )\n",
    "  img2 = tf.clip_by_value(img2, clip_value_min=0., clip_value_max=1.) \n",
    "  \n",
    "  return img1, img2\n",
    "\n",
    "def process_path(file_path):\n",
    "  # Load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img1, img2 = decode_img(img)\n",
    "  return img2, img1\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(4)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_ds))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(4):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  img = image_batch[i].numpy() \n",
    "  print(img.max())\n",
    "  # img *= 255\n",
    "  # i = i.astype(\"uint8\")\n",
    "  plt.imshow(img)\n",
    "#   label = label_batch[i]\n",
    "  plt.title(\"img\")\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build encoder decoder model using keras functional API\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, BatchNormalization, UpSampling2D, GaussianNoise\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def create_model():\n",
    "  x = Input(shape=(height, width, 3))\n",
    "# Encoder\n",
    "  # noise = GaussianNoise(0.6)(x)\n",
    "  e_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "  pool1 = MaxPooling2D((2, 2), padding='same')(e_conv1)\n",
    "  batchnorm_1 = BatchNormalization()(pool1)\n",
    "  e_conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(batchnorm_1)\n",
    "  pool2 = MaxPooling2D((2, 2), padding='same')(e_conv2)\n",
    "  batchnorm_2 = BatchNormalization()(pool2)\n",
    "  e_conv3 = Conv2D(16, (3, 3), activation='relu', padding='same')(batchnorm_2)\n",
    "  h = MaxPooling2D((2, 2), padding='same')(e_conv3)\n",
    "# Decoder\n",
    "  d_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(h)\n",
    "  up1 = UpSampling2D((2, 2))(d_conv1)\n",
    "  d_conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1)\n",
    "  up2 = UpSampling2D((2, 2))(d_conv2)\n",
    "  d_conv3 = Conv2D(16, (3, 3), activation='relu', padding='same')(up2)\n",
    "  up3 = UpSampling2D((2, 2))(d_conv3)\n",
    "  r = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up3)\n",
    "  \n",
    "  model = Model(x, r)\n",
    "  model.compile(optimizer='adam', loss='mse')\n",
    "  return model\n",
    "gaussian_auto_encoder = create_model()\n",
    "gaussian_early_stop = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_history = gaussian_auto_encoder.fit(train_ds,validation_data= val_ds, epochs=200, batch_size=32, callbacks=[gaussian_early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_auto_encoder.save(\"tfmodels/gaussian_auto_encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = next(iter(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0][:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = gaussian_auto_encoder.predict(i[0][:1])\n",
    "o = tf.clip_by_value(o[0], clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 \n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.gray()\n",
    "\n",
    "for i in range(n): \n",
    "  # display original + noise \n",
    "  bx = plt.subplot(3, n, i + 1) \n",
    "  plt.title(\"original + noise\") \n",
    "  plt.imshow(tf.squeeze(x_test_noisy[i])) \n",
    "  ax.get_xaxis().set_visible(False) \n",
    "  ax.get_yaxis().set_visible(False) \n",
    "  \n",
    "  # display reconstruction \n",
    "  cx = plt.subplot(3, n, i + n + 1) \n",
    "  plt.title(\"reconstructed\") \n",
    "  plt.imshow(tf.squeeze(decoded_imgs[i])) \n",
    "  bx.get_xaxis().set_visible(False) \n",
    "  bx.get_yaxis().set_visible(False) \n",
    "  \n",
    "  # display original \n",
    "  ax = plt.subplot(3, n, i + 2*n + 1) \n",
    "  plt.title(\"original\") \n",
    "  plt.imshow(tf.squeeze(x_test[i])) \n",
    "  ax.get_xaxis().set_visible(False) \n",
    "  ax.get_yaxis().set_visible(False) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68ba60249a85c0ecf3a298dfdd772960cabc5178b528ab7c7b7cd8ed3465f734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
